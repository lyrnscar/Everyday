3.3
对训练数据和测试数据进行相同的缩放
如果分别进行缩放，数据集看起来移动不一致，随意的改变了数据的排列
测试集的大小不应当对处理方式有影响
可以使用fit_transform来提高效率（相比于方法链）

3.4
使用minmaxscaler对cancer数据集进行缩放，缩放后效果非常显著
所有预处理的类都具有相同的接口，都包含fit和transform方法

4
降维，特征提取与流形学习
为实现可视化，压缩数据，寻找信息量更大的数据表示，最常见的是pca
还有nmf非负矩阵分解和t-SNE前者用于特征提取，后者用于二维散点图可视化

4.1
主成分分析是一种旋转数据集的方法，旋转后特征在统计上不相关，对新特征解释数据的重要性选择一个子集

在例子中，算法首先找到方差最大的方向标记为成分1，数据中包含最多信息的方向，然后找到与这个方向正交的第二个方向且包含最多信息的方向，高维空间中无穷多
利用这一过程找到的方向被称为主成分，一般来说主成分个数与原始特征相同
在例子中，旋转之前减去数据平均值，使变换后的数据以0为中心，进行旋转，使第一主成分与x轴平行，第二主成分与y轴平行
两个坐标轴不相关，除了对角线，相关矩阵全部为0
选择保留第一个主成分，保留了这一个方向，反向旋转添加回数据，这个例子中的变换有时用于去除噪声，或者将主成分中保留信息可视化

4.1.1
pca常见应用是将高维数据可视化
对cancer应用，可视化，对每个特征分别计算两个类别直方图，如果重叠较多则说明特征没什么信息量，如果交集很小则特征信息量大
先使用standardscaler缩放数据，使每个特征方差均为1
pca与预处理类似，先实例化，调用fit方法找到主成分，然后transform旋转并降维
默认情况下pca仅旋转数据但保留所有的主成分，可以指定想保留的个数n_components

pca无监督，寻找旋转方向时没有用到任何类别信息，只是观察数据中的相关性
一个缺点在于，通常不易对图中两个轴作出解释，对应的是原始特征的组合，往往比较复杂
components_属性中保存主成分，每行对应一个主成分，按重要性排序
在cancer的第一个主成分中，所有特征符号相同，存在普遍的相关性，第二个主成分有正有负，这种混合使得解释坐标轴变得困难
