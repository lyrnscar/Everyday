4.1.2
pca用于特征提取，特征提取的思想是可以找到一种数据表示，比给定的原始表示更适合于分析
特征提取的一个应用实例是图像，图像即rgb
例子为wild数据集labeled faces标记人脸中的人脸图像
人脸识别一个常见任务是看某个前所未见的人脸是否属于数据库中的某个已知人物
常见方案：构建一个分类器，每个人都是一个单独的类别，缺陷是有许多不同的人，同一个人的图像很少，大多数分类器的选择都很困难，添加人物时需要重建模型
简单解决方式：使用单一最近邻分类器，但在例子中精度较低
这时考虑使用pca，度量人脸相似度，计算原始像素空间距离不可取，用像素灰度值比较
希望沿着主成分方向的距离可以提高精度，使用pca白化，效果与standardscaler相同，将主成分缩小到相同的尺度，缩放数据使其形状是圆形而不是椭圆
在例子中提取100个主成分，利用最近邻分类器将精度由0.27提高到0.36
pcb提取的主成分对应输入空间中的方向，但难以理解，pca模型基于像素，人脸相对位置和明暗程度都对两张图像在像素表示中的相似程度有很大影响
算法对数据的解释通常与人类的解释方式不同
pca先旋转数据，然后删除方差较小的成分，另一种解释是尝试找到一些数字，将测试点表示为主成分加权求和，第一个人脸主成分乘系数加第二个加……
另一种理解方式：仅使用一些成分对原始数据进行重建，使用的主成分越多，图像中保留越多细节，人脸方向，明暗程度
如cancer数据集只使用前两个主成分可视化，看不到类别分界

4.2
nmf非负矩阵分解目的在于提取有用的特征，原理类似pca，试图将每个数据点写成一些分量的加权求和，pca中想要的是正交分量，并且能够解释尽可能多的数据方差，nmf中希望分量和系数均为非负，这种方法只适用于每个特征非负的数据，非负分量的非负求和不可能变为负值
将数据分解成非负加权求和的过程对多个独立源相加叠加的数据特别有用
相比pca，nmf得到的分量更容易解释，负的分量和系数可能会导致难以解释的抵消效应

4.2.1
将nmf应用于模拟数据，与pca不同，nmf能对数据进行操作，数据相对原点的位置对nmf很重要，可将提取出来的非负分量看作是从原点到数据的方向
在二维玩具数据上，对于两个分量的nmf，所有数据点都可以写成这两个分量的正数组合，如果有足够多的分量完美重建数据（分量个数与特征个数相同）算法会选择指向数据极值的方向
仅使用一个分量，nmf会创建一个指向平均值的分量，便于解释。
与pca不同，减少分量个数不仅会删除一些方向而且会创建一组完全不同的分量
nmf所有分量地位平等，不存在第一第二，使用了随机初始化，根据随机种子不同可能产生不同的结果，在简单的情况下所有数据可以完美解释，在复杂的情况下，影响会很大

4.2.2将nmf应用到人脸图像
将nmf应用到labeled faces
主要参数是想提取的分量个数，通常小于输入特征的个数
在例子中，反向变换的数据质量与pca类似，但要稍差一些，因为pca找到的是重建最佳方向
nmf通常并不用于对数据进行重建或编码，用于在数据中寻找有趣模式
在例子中提取15个分量，这些分量都是正的，因此比pca分量更像人脸原型，分量3系数较大的人脸提取的都是向右看的人脸，分量7系数较大的人脸都向左看，如前所述，这种模式最适合具有叠加结构的数据，包括音频，基因表达，文本数据
在模拟信号源的例子上，先将数据混合成100维，用nmf还原三个信号，对比使用pca，nmf在发现原始信号源时得到不错的结果，pca失败了

其他算法包括ica独立成分分析，fa因子分析，稀疏编码（字典学习）
